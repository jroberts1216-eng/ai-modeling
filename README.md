# Local LLM Example

This repo demonstrates how to run a small language model (LLM) using Hugging Face Transformers.

## Usage

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

2. Run the model:
   ```bash
   python llm_inference.py
   ```

## Model

Uses `tiiuae/falcon-rw-1b`, a lightweight open-access model suitable for local use.
